{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec, Word2Vec\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "from smart_open import smart_open\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_concept_tagged = re.compile(\n",
    "    r\"<c>(?P<phrase>[^<]*)</c>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_oneWord(w):\n",
    "    return w.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2internal(raw_textual_unit):\n",
    "    if not raw_textual_unit.istitle():\n",
    "        raw_textual_unit = raw_textual_unit.lower()\n",
    "    return raw_textual_unit.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_rule(word, count, min_count):\n",
    "    if re_concept_tagged.match(word):\n",
    "        return gensim.utils.RULE_KEEP\n",
    "    return gensim.utils.RULE_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_concept_gensim(w):\n",
    "    return '<c>%s</c>' % to_oneWord(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_concept_natural_lower(w):\n",
    "    return to_concept_natural(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_list(superspan):\n",
    "    if superspan['tag'] == 'superspan':\n",
    "        return [to_concept_gensim(span['text']) for span in superspan['spans']]\n",
    "    else:\n",
    "        return [superspan['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedTextualUnits(superspan):\n",
    "    textual_units_raw = get_candidate_list(superspan)\n",
    "    textual_units_normalized = [word2internal(raw_textual_unit) for raw_textual_unit in textual_units_raw]\n",
    "\n",
    "    return textual_units_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_nonLetter = re.compile('[^a-zA-Z]')\n",
    "\n",
    "def removeNonLetter(doc, replaceWithSpace=False):\n",
    "    if replaceWithSpace:\n",
    "        doc = re.sub(re_nonLetter, ' ', doc)\n",
    "    else:\n",
    "        doc = re.sub(re_nonLetter, '', doc)\n",
    "    # doc = ''.join(i for i in text if ord(i)<128)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_candidateLists(superspan_sequence):\n",
    "    superspan_sequence_removed_letters = [superspan for superspan in superspan_sequence if removeNonLetter(superspan['text'])]\n",
    "    return [getNormalizedTextualUnits(superspan) for superspan in superspan_sequence_removed_letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineSuperWordSequenceAsWordPair(object):\n",
    "    def __init__(self, source, limit=None):\n",
    "        self.source = source\n",
    "        self.limit = limit\n",
    "\n",
    "    def __iter__(self):\n",
    "        with smart_open(self.source) as fin:\n",
    "            for line in itertools.islice(fin, self.limit):\n",
    "                superspan_sequence = get_list_of_candidateLists(json.loads(line))\n",
    "                for i in range(len(superspan_sequence)):\n",
    "                    for j in range(i + 1, min(i + WINDOW_SIZE + 1, len(superspan_sequence))):\n",
    "                        for candidate_i in superspan_sequence[i]:\n",
    "                            for candidate_j in superspan_sequence[j]:\n",
    "                                yield [candidate_i, candidate_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "input_file_name = 'arxiv_abstracts_10000.txt'\n",
    "extensionless_input_file_name = input_file_name.split('.')[0]\n",
    "input_file_path = f'{data_dir}/{input_file_name}'\n",
    "\n",
    "supersequence_path = f'{data_dir}/{extensionless_input_file_name}_superspan_sequence.json'\n",
    "\n",
    "model_save_path = f'{data_dir}/{extensionless_input_file_name}_embedding.bin'\n",
    "\n",
    "file = supersequence_path\n",
    "model = Word2Vec(LineSuperWordSequenceAsWordPair(file), min_count=30, window=WINDOW_SIZE, sg=1, iter=5, workers=32, hs=1, negative=0, trim_rule=trim_rule)\n",
    "\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se",
   "language": "python",
   "name": "se"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
