{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "input_file_name = 'arxiv_abstracts_10000.txt'\n",
    "extensionless_input_file_name = input_file_name.split('.')[0]\n",
    "input_file_path = f'{data_dir}/{input_file_name}'\n",
    "\n",
    "supersequence_path = f'{data_dir}/{extensionless_input_file_name}_superspan_sequence.json'\n",
    "model_save_path = f'{data_dir}/{extensionless_input_file_name}_embedding.bin'\n",
    "concept_feature_path = f'{data_dir}/{extensionless_input_file_name}_econ_feature.txt'\n",
    "concept_score_path = f'{data_dir}/{extensionless_input_file_name}_score_list.bin'\n",
    "\n",
    "concept_representation_path = f'{data_dir}/{extensionless_input_file_name}_concept_representation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_concept_tagged = re.compile(\n",
    "    r\"<c>(?P<phrase>[^<]*)</c>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(model_save_path)\n",
    "concept_list = [w for w in model.wv.index2word if re_concept_tagged.match(w)]\n",
    "\n",
    "concept_lowered2score = defaultdict(lambda :1)\n",
    "\n",
    "try:\n",
    "    concept_score_list = pickle.load(open(concept_score_path, 'r'))\n",
    "    concept2score = dict(zip(concept_list[:len(concept_score_list)], concept_score_list))\n",
    "    concept_lowered2score = {c.lower(): max([s for c, s in c_s]) for c, c_s in\n",
    "                             groupby(sorted(concept2score.items(), key=lambda t: t[0]), key=lambda t: t[0])}\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_lower = {k.lower():v for k,v in model.wv.vocab.items()}\n",
    "concept_lower2Concept = {w:model.wv.index2word[vocab_lower[w].index] for w in vocab_lower}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(supersequence_path) as fin:\n",
    "    supersequences = [i for i in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_nonLetter = re.compile('[^a-zA-Z]')\n",
    "\n",
    "def removeNonLetter(doc, replaceWithSpace=False):\n",
    "    if replaceWithSpace:\n",
    "        doc = re.sub(re_nonLetter, ' ', doc)\n",
    "    else:\n",
    "        doc = re.sub(re_nonLetter, '', doc)\n",
    "    # doc = ''.join(i for i in text if ord(i)<128)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_oneWord(w):\n",
    "    return w.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_concept_gensim(w):\n",
    "    return '<c>%s</c>' % to_oneWord(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_list(superspan):\n",
    "    if superspan['tag'] == 'superspan':\n",
    "        return [to_concept_gensim(span['text']) for span in superspan['spans']]\n",
    "    else:\n",
    "        return [superspan['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2internal(raw_textual_unit):\n",
    "    if not raw_textual_unit.istitle():\n",
    "        raw_textual_unit = raw_textual_unit.lower()\n",
    "    return raw_textual_unit.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedTextualUnits(superspan):\n",
    "    textual_units_raw = get_candidate_list(superspan)\n",
    "    textual_units_normalized = [word2internal(raw_textual_unit) for raw_textual_unit in textual_units_raw]\n",
    "    return textual_units_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_superspan_sequence(superspan_sequence):\n",
    "    superspan_sequence_removed_letters = [superspan for superspan in superspan_sequence if removeNonLetter(superspan['text'])]\n",
    "    return superspan_sequence_removed_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_concept_natural(w):\n",
    "    # return w\n",
    "    return re.sub(r'</?c>', '', w).replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_concept_natural_lower(w):\n",
    "    return to_concept_natural(w.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIsDominatedScore(sequence, superspan_sequence, model=model):\n",
    "    score = 0\n",
    "    for concept, superspan in zip(sequence, superspan_sequence):\n",
    "        if re_concept_tagged.match(concept):\n",
    "            concept = concept.lower()\n",
    "            covered_concepts = set()\n",
    "            try:\n",
    "                covered_neighbor_word2sim = {covered_concept.lower(): sim for covered_concept, sim in model.most_similar(model.wv.index2word[vocab_lower[concept1].index], topn=TOPN, restrict_vocab=restrict_vocab, partition_only=True) if sim > BASIC_THRESHOLD and to_concept_natural_lower(concept) in to_concept_natural_lower(covered_concept)}\n",
    "                for other_concept in getNormalizedTextualUnits(superspan):\n",
    "                    if other_concept.lower() in covered_neighbor_word2sim:\n",
    "                        covered_concepts.add(other_concept)\n",
    "                        continue\n",
    "\n",
    "                score += len(covered_concepts)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedLengthScore(sequence, superspan_sequence):\n",
    "    score = sum([len(to_concept_natural_lower(w).split('_')) / float(len(superspan['text'].split())) for w, superspan in zip(sequence, superspan_sequence)])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConceptQualityScore(sequence):\n",
    "    score = sum([concept_lowered2score.get(w.lower(), 0) for w in sequence])\n",
    "    # todo: add length rewards\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    if not isinstance(array, np.ndarray):\n",
    "        array = np.array(array, dtype=np.float)\n",
    "    return (array - np.min(array)) / (np.max(array) - np.min(array) + np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEndsWithScore(sequence, superspan_sequence):\n",
    "    score = sum([1 if to_concept_natural_lower(superspan['text']).endswith(to_concept_natural_lower(span).split('_')[-1]) else 0 for span, superspan in zip(sequence, superspan_sequence)])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_DOMINATED_COEFF = -20\n",
    "\n",
    "def select_best(superspan_sequence, ALPHA = .5, BETA = .51, GAMMA = 10, model=model):\n",
    "    # combine all choices and score each one, select best\n",
    "    possible_sequence_bylength = defaultdict(list)\n",
    "    for span in getNormalizedTextualUnits(superspan_sequence[0]):\n",
    "        possible_sequence_bylength[0] += [[span]]\n",
    "    for i in range(1, len(superspan_sequence)):\n",
    "        current_superSpan = superspan_sequence[i]\n",
    "        # todo: take in non overlapping textual units within same superspan\n",
    "        for span in getNormalizedTextualUnits(current_superSpan):\n",
    "            possible_sequence_bylength[i] += [previous_possible_sequence + [span] for previous_possible_sequence in possible_sequence_bylength[i-1]]\n",
    "    possible_sequences = possible_sequence_bylength[len(superspan_sequence) - 1]\n",
    "    model_scores = normalize(model.score(possible_sequences))\n",
    "\n",
    "    # is add, because is computing negative log likelihood\n",
    "\n",
    "    # if two words are similar in the same span, the contained words are dominated and will not be selected\n",
    "    concept_quality_scores = normalize([getConceptQualityScore(possible_sequence) for possible_sequence in possible_sequences])\n",
    "    concept_length_scores = normalize([getNormalizedLengthScore(possible_sequence, superspan_sequence) for possible_sequence in possible_sequences])\n",
    "    concept_endswith_scores = normalize([getEndsWithScore(possible_sequence, superspan_sequence) for possible_sequence in possible_sequences])\n",
    "    concept_is_dominated_scores = normalize([getIsDominatedScore(possible_sequence, superspan_sequence, model) for possible_sequence in possible_sequences])\n",
    "\n",
    "    scores = model_scores + ALPHA * concept_quality_scores + BETA * concept_length_scores + GAMMA * concept_endswith_scores + IS_DOMINATED_COEFF * concept_is_dominated_scores\n",
    "\n",
    "    original_sent = ' '.join(superspan['text'] for superspan in superspan_sequence)\n",
    "#     print('\\n'.join(['%s %s %s %s %s %s %s' % t for t in zip(possible_sequences, model_scores, concept_quality_scores, concept_length_scores, concept_endswith_scores, concept_is_dominated_scores, scores)]))\n",
    "#     print(original_sent)\n",
    "#     print(sorted(zip(possible_sequences, scores), key=lambda x: x[1], reverse=True)[0][0])\n",
    "\n",
    "    return sorted(zip(possible_sequences, scores), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = .5\n",
    "BETA = .51\n",
    "GAMMA = 10\n",
    "MAX_CHOICES = 5000\n",
    "\n",
    "def process_superspan_sequence(superspan_sequence, ALPHA=.5, BETA=.51, GAMMA=10, model=model):\n",
    "    superspan_sequence = get_cleaned_superspan_sequence(superspan_sequence)\n",
    "    recognized_spans = []\n",
    "\n",
    "    current_start = 0\n",
    "    num_current_choices = 1\n",
    "\n",
    "    for i, current_superSpan in enumerate(superspan_sequence):\n",
    "        # compute max. choice\n",
    "        num_current_choices *= len(getNormalizedTextualUnits(current_superSpan))\n",
    "\n",
    "        # if MAX_CHOICES is reached\n",
    "        if num_current_choices >= MAX_CHOICES:\n",
    "            # score all sentence, merge into result\n",
    "            recognized_spans += select_best(superspan_sequence[current_start:i + 1], ALPHA=ALPHA, BETA=BETA, GAMMA=GAMMA, model=model)\n",
    "            current_start = i + 1\n",
    "            num_current_choices = 1\n",
    "\n",
    "    if superspan_sequence[current_start:]:\n",
    "        recognized_spans += select_best(superspan_sequence[current_start:], model=model)\n",
    "\n",
    "    return ' '.join(recognized_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:00<00:00, 164.98it/s]\n"
     ]
    }
   ],
   "source": [
    "indexes = range(len(supersequences))\n",
    "\n",
    "model.init_sims()\n",
    "\n",
    "with open(concept_representation_path, 'w') as f:\n",
    "    for i in tqdm(indexes):\n",
    "        segmentation = process_superspan_sequence(json.loads(supersequences[i]), model=model)\n",
    "        f.write(segmentation + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se",
   "language": "python",
   "name": "se"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
